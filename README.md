# 游냕 Birdy AI: Evoluci칩n del Cerebro Neuroevolutivo
Este documento detalla la progresi칩n de la arquitectura de la red neuronal aplicada a nuestro proyecto Birdy, un sistema de aprendizaje por refuerzo donde una poblaci칩n de p치jaros evoluciona para dominar un entorno din치mico.

## LOG DE EVOLUCI칍N: BIRDY NEURAL NETWORK

| FASE | ARQUITECTURA | PESOS | DESCRIPCI칍N T칄CNICA |
| :--- | :--- | :--- | :--- |
| **01. Prototipo** | **3 - 5 - 1** | ~20 | **Reflejo B치sico:** Solo esquiva tuber칤as. Entradas: Distancia X, Distancia Y, y Velocidad. |
| **02. Expansi칩n** | **11 - 16 - 1** | ~192 | **Percepci칩n Total:** A침adimos Espadas, Monedas y PowerUps con sensores individuales para cada uno. |
| **03. Actual (Deep)**| **9 - 10 - 6 - 1**| 156 | **Estratega:** Dos capas ocultas. Capacidad de priorizar: "Esquivar espada > Recoger moneda". |

---

### Cambios Clave en la L칩gica de Entrenamiento

* **De Destrucci칩n a Persistencia:** Los objetos ya no mueren al ser tocados (`dokill=False`). Usamos `hit_items` por p치jaro para que la horda compita en igualdad de condiciones.
* **Normalizaci칩n $[0, 1]$:** Todos los inputs (distancias y velocidades) se escalan seg칰n el tama침o de la pantalla para estabilizar los gradientes de la red.
* **Jerarqu칤a de Fitness:**
    * **Vivir:** +1 (Supervivencia)
    * **Moneda:** +100 (Incentivo)
    * **PowerUp:** +500 (Prioridad)
    * **Espada:** -300 (Castigo por da침o) 
    > **Nota:** Castigos bajos provocan saltos constantes en el p치jaro ya que esta es la mejor estrategia si solo nos importa sobrevivir.

---

### Configuraci칩n de Capas Actual (9-10-6-1)
1. **Input (9):** [PipeX, PipeY, CoinX, CoinY, PwX, PwY, SwX, SwY, SpeedY]
2. **Hidden 1 (10):** Extracci칩n de patrones de proximidad.
3. **Hidden 2 (6):** Toma de decisiones l칩gica y estrat칠gica.
4. **Output (1):** Decisi칩n binaria de salto (Funci칩n Sigmoide > 0.5).

---

### Arquitectura de Alto Rendimiento

* **Motor Dual CPU/GPU (Motor Agn칩stico):** El sistema detecta autom치ticamente si hay una GPU compatible. 
    * Usa **CuPy** (CUDA) para poblaciones masivas (>10.000).
    * Usa **NumPy** para pruebas ligeras en CPU.
* **Vectorizaci칩n de Ciclo Completo:** Hemos eliminado los bucles `for` en la l칩gica de los p치jaros. El cerebro (IA), la f칤sica y las colisiones se calculan como operaciones de matrices de una sola instrucci칩n, independientes a los sprites.
* **Compactaci칩n Din치mica (Slicing):** A medida que los p치jaros mueren, el motor "recorta" las matrices de c치lculo. Si quedan 800 vivos de 1.000.000, la GPU solo procesa esos 800, acelerando los FPS exponencialmente al final de cada generaci칩n.



### Optimizaciones de Memoria

* **Descarga Selectiva (Zero-Bottleneck):** Solo se transfieren de la VRAM (GPU) a la RAM (CPU) los datos de los 10 mejores p치jaros y el l칤der para su renderizado en Pygame. El resto de la poblaci칩n permanece en la GPU, eliminando cuellos de botella.
* **Detecci칩n de Colisiones AABB Vectorizada:** Las colisiones con 칤tems y tuber칤as se calculan comparando el array de posiciones `Y` completo contra las coordenadas de los obst치culos, detectando miles de choques en microsegundos.
* **Persistencia H칤brida:** Los pesos se guardan en formato `.npz` est치ndar de NumPy. Al cargar, el sistema los "sube" a la GPU autom치ticamente mediante `xp.asarray()`, permitiendo entrenar en un PC potente y ejecutar el modelo en cualquier otro.

---

## Benchmark: El Salto a la Computaci칩n Masiva

Tras someter a prueba las tres iteraciones del motor, los resultados demuestran que la optimizaci칩n ha transformado el sistema de una simulaci칩n limitada a un motor de vida artificial a escala masiva.

### Comparativa de Escalabilidad Real

![Architecture Comparison](architecture_comparison_60fps.png)

| Arquitectura | L칤mite 60 FPS | Tiempo (1M p치jaros) | Mejora vs V1 | Complejidad |
| :--- | :--- | :--- | :--- | :--- |
| **V1: OOP (Python)** | **~326 p치jaros** | ~45,50 s (Te칩rico) | **Base** | $O(n)$ Lineal Ineficiente |
| **V2: DOD (CPU)** | **~25.141 p치jaros** | ~0,68 s | **x66** faster | $O(n)$ SIMD Vectorizado |
| **V2: DOD (GPU)** | **~392.143 p치jaros** | **~0,07 s** | **x650** faster | **Sub-lineal / Paralelo** |

1.  **Paradigma DOD (Data-Oriented Design):** Eliminamos la gesti칩n de "objetos" individuales para procesar **arrays contiguos**. Esto maximiza la **Cache Locality** y permite el uso de instrucciones **SIMD**, logrando que la versi칩n CPU sea **66x m치s r치pida** que la original.
2.  **Paralelismo CUDA:** La GPU lanza miles de hilos simult치neos, permitiendo que el coste de procesar 10.000 p치jaros sea casi id칠ntico al de 200. El l칤mite actual es la **VRAM** (para una **RTX3060 laptop**: *OutOfMemory a los 30M de individuos*), no la velocidad de c치lculo.

> **Conclusi칩n:** La arquitectura actual permite simular en segundos lo que antes requerir칤a horas de procesamiento.


## RETOS T칄CNICOS Y "GOTCHAS" DE LA OPTIMIZACI칍N


### 1. Diferenciaci칩n: Computaci칩n Masiva vs. Dibujo Selectivo

Uno de los mayores desaf칤os fue entender que la escala de la simulaci칩n no puede ser la misma que la de la visualizaci칩n.

* **Computaci칩n "Ciega" (GPU):** La simulaci칩n f칤sica, las colisiones y las decisiones de la IA ocurren para el **1.000.000 de p치jaros** simult치neamente en la VRAM. A la GPU no le importa "ver" los p치jaros; solo procesa vectores num칠ricos de forma invisible y masiva.
* **Dibujo "Selectivo" (CPU/Pygame):** Dibujar un mill칩n de sprites colapsar칤a el bus PCIe y saturar칤a la pantalla. 
    * **La Estrategia:** Solo "bajamos" de la GPU a la CPU (v칤a `.asnumpy()`) los datos de una **muestra representativa** (el Top 10 y el l칤der).
    * **Resultado:** Mientras la tarjeta gr치fica calcula el destino de un mill칩n de individuos, el procesador solo se encarga de pintar 11 sprites, manteniendo los FPS estables.

### 2. Cambio de Paradigma: De Orientaci칩n a Objetos (OOP) a Orientaci칩n a Datos (DOD)


* **El Problema de la OOP (Object-Oriented):** Originalmente, cada p치jaro era una instancia de la clase Birdy. Esto significaba tener 1.000.000 de objetos dispersos en la memoria. Para la CPU, saltar de un objeto a otro para leer su self.y es extremadamente lento debido a los "Cache Misses" (el procesador pierde tiempo buscando datos lejanos).

* **La Soluci칩n DOD (Data-Oriented):** Hemos destruido la idea del p치jaro como "objeto individual". Ahora, la poblaci칩n son Arrays Contiguos de datos puros (bird_y, bird_speed, bird_alive).
    * Los datos est치n empaquetados linealmente en la memoria (VRAM).

    * El hardware puede leer miles de posiciones de una sola vez porque est치n una al lado de la otra.

Resultado: Ya no le decimos a cada p치jaro "actualiza tu f칤sica", le decimos al procesador "suma la gravedad a todo este bloque de un mill칩n de n칰meros".

### 3. salto a la computaci칩n masiva en GPU 

#### 3.1. El Desaf칤o del Mapeo de 칈ndices (Compactaci칩n)
* **Problema:** Al optimizar el rendimiento filtrando solo los p치jaros vivos (`idx_alive`), perdimos la relaci칩n directa con los 칤ndices originales de la poblaci칩n. Esto provoc칩 errores de `IndexError` al intentar acceder a la matriz de decisiones (peque침a) usando 칤ndices globales (grandes).
* **Soluci칩n:** Implementamos un sistema de "Mapeo Relativo". El l칤der siempre se identifica primero de forma global, pero sus inputs se extraen usando su posici칩n relativa dentro del buffer de supervivientes.


#### 3.2. El Desaf칤o del Mapeo de 칈ndices y Compactaci칩n
* **Problema:** Al trabajar con orientaci칩n a datos y filtrar solo los vivos (idx_alive), perdimos la relaci칩n directa con la identidad original de cada agente. Los 칤ndices globales (del 0 al 1.000.000) ya no serv칤an para indexar las nuevas matrices compactas de supervivientes, causando errores de IndexError.

* **Soluci칩n:** Implementamos un sistema de Mapeo Relativo. 
    * Los c치lculos masivos se hacen en "espacio compacto" (solo vivos).
    * La identidad del l칤der se mantiene globalmente, pero para extraer su red neuronal o su visi칩n, calculamos su posici칩n relativa dentro del bloque de supervivientes. Es una transici칩n constante entre la visi칩n global (poblaci칩n) y la visi칩n local (datos procesados).

